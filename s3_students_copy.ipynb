{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Anonymization and Privacy-Enhancing Technologies (PETs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Goals\n",
    "- Understand what data anonymization is and why it matters.\n",
    "- Apply anonymization techniques to structured, text and audio data.\n",
    "- Understand how anonymization supports compliance with privacy laws (GDPR, CCPA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ” Introduction to Data Anonymization\n",
    "\n",
    "- **Data anonymization** removes personally identifiable information (PII) from datasets.\n",
    "- **Pseudonymization** retains a link to identity (e.g., using a key); anonymization does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§° Techniques for Anonymizing Different Data Types\n",
    "- **Structured Data**: k-anonymity, l-diversity, t-closeness\n",
    "- **Text Data**: Named Entity Recognition (NER) + masking\n",
    "- **Images**: Face blurring, pixelation\n",
    "- **Audio**: Voice masking, pitch shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“œ Legal Relevance\n",
    "- **GDPR & CCPA**: Require data minimization and protection.\n",
    "- Anonymization helps avoid processing 'personal data' under these laws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 1: Structured Data Anonymization (k-Anonymity)\n",
    "\n",
    "### ðŸ’¡ Task 1 \n",
    "\n",
    "#### Description:\n",
    "You are provided with a structured dataset (CSV file) containing personal attributes like Age, Education, Occupation, Relationship, Sex, and Country. Your task is to anonymize this data using **k-anonymity** by binning continuous data (like Age) and generalizing or masking quasi-identifiers such as Country or Occupation. Then assess whether individual identities could still be inferred.\n",
    "\n",
    "\n",
    "- Generalize and group quasi-identifiers (e.g., Age and Country)\n",
    "- Ensure each combination of quasi-identifiers occurs at least **k** times\n",
    "- Evaluate anonymity level before and after transformation\n",
    "\n",
    "\n",
    "Click [***here***](https://github.com/SanthwanaT/Seminar-3/blob/main/structured_data.csv) to understand more about the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn spacy opencv-python-headless matplotlib librosa pydub\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Task 1.1 : Upload and Load the Dataset \n",
    "\n",
    "- Upload the dataset from your local machine to Colab.\n",
    "- Read it into a pandas DataFrame.\n",
    "- Preview the first few rows.\n",
    "\n",
    "Option 2: You're not in Colab\n",
    "Then do not use from google.colab import files. Instead, use standard file upload or path loading methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset from  drive link \n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded CSV file\n",
    "import pandas as pd\n",
    "\n",
    "data =   # Use the name of the uploaded file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Task 1.2 : Clean and Standardize String Columns\n",
    "\n",
    "- Whitespace and inconsistent casing can prevent accurate mapping.\n",
    "- Standardize entries in Education, Occupation, and Country:\n",
    "- Remove extra spaces.\n",
    "- Capitalize words consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace and convert to title case\n",
    "for col in ['Education', 'Occupation', 'Country']:\n",
    "    data[col] = data[col].str.strip().str.title()\n",
    "\n",
    "# View distinct cleaned values\n",
    "data[['Education', 'Occupation', 'Country']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Task 1.3: Bin the 'Age' Attribute into Groups\n",
    "\n",
    "- Convert numerical Age into intervals (Bins : e.g., \"21â€“30\", \"31â€“40\"). Bins should be taken from 0 to 100. \n",
    "- This reduces granularity and increases privacy.\n",
    "- Binning helps meet the k-anonymity requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and labels\n",
    "bins = \n",
    "labels = \n",
    "\n",
    "# Apply binning\n",
    "data['Age_group'] = \n",
    "\n",
    "# View the binned age groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Task 1.4: Generalize Quasi-Identifiers\n",
    "\n",
    "- Replace specific values with general categories:\n",
    "  - Education: into { 'Bachelors': 'HigherEd', 'Masters': 'HigherEd', 'Doctorate': 'HigherEd',\n",
    "    'Hs-Grad': 'HighSchool', 'Some-College': 'HighSchool',\n",
    "    '11Th': 'Dropout', '9Th': 'Dropout', '7Th-8Th': 'Dropout',\n",
    "    'Assoc-Acdm': 'Associate', 'Assoc-Voc': 'Associate'}\n",
    "\n",
    "  - Occupation: into broader fields like { Adm-Clerical': 'Clerical', 'Exec-Managerial': 'Management',\n",
    "    'Handlers-Cleaners': 'Manual Labor', 'Prof-Specialty': 'Professional',\n",
    "    'Other-Service': 'Service', 'Sales': 'Sales',\n",
    "    'Craft-Repair': 'Skilled Trade', 'Transport-Moving': 'Transport',\n",
    "    'Farming-Fishing': 'Agriculture', 'Machine-Op-Inspct': 'Manufacturing' }\n",
    "\n",
    "  - Country: into geographic regions { 'United-States': 'North America', 'Cuba': 'Latin America',\n",
    "    'Jamaica': 'Latin America', 'India': 'Asia', 'Mexico': 'Latin America'}\n",
    "    \n",
    "- These fields are quasi-identifiers and must be generalized to protect identity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalize Education\n",
    "education_map = \n",
    "\n",
    "# Generalize Occupation\n",
    "occupation_map = \n",
    "\n",
    "# Generalize Country to Region\n",
    "region_map = \n",
    "\n",
    "# Apply generalizations\n",
    "data['Education_gen'] = \n",
    "data['Occupation_gen'] =\n",
    "data['Region'] =\n",
    "\n",
    "# View generalized fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ’¡ Task 1.5: Apply k-Anonymity Check\n",
    "\n",
    "- Define the list of quasi-identifiers (QIs). (eg : Age_group, Education_gen, Occupation_gen, Relationship, Sex, Region)\n",
    "- Group data by QIs and count the frequency of each group.\n",
    "- Identify combinations that appear less than k times (violating anonymity).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the k value\n",
    "k = 3\n",
    "\n",
    "# Define quasi-identifier columns\n",
    "qi_columns =\n",
    "\n",
    "# Count occurrences of each QI group\n",
    "grouped = \n",
    "\n",
    "# Identify violating combinations\n",
    "violations = \n",
    "\n",
    "print(f\"\\nRows violating {k}-anonymity:\")\n",
    "violations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ’¡ Task 1.6: Save and Download Anonymized Data\n",
    "\n",
    "- Select only the anonymized/generalized columns.\n",
    "- Save the result to a new CSV.\n",
    "- Provide download link for student use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the anonymized fields\n",
    "anonymized_columns = \n",
    "data_anonymized =\n",
    "\n",
    "# Save the anonymized dataset\n",
    "\n",
    "\n",
    "# Download the CSV file in Colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ” What are l-Diversity and t-Closeness?\n",
    "\n",
    "- l-Diversity extends k-anonymity by ensuring diversity in sensitive attributes (e.g., income, disease) within each group.\n",
    "- t-Closeness ensures that the distribution of sensitive values in each group is close to the overall distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ’¡ Task 1.7:  Apply l-Diversity\n",
    "\n",
    "- Ensure that each group (based on quasi-identifiers) has at least l distinct values of the sensitive attribute. This protects against homogeneity attacks.\n",
    "\n",
    "### ðŸ§¾ Instructions:\n",
    "- Define quasi-identifiers (QI) and the sensitive attribute (e.g., 'Education').\n",
    "- Group by QI.\n",
    "- For each group, count the number of unique values in the sensitive attribute.\n",
    "- Check if this count â‰¥ l.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l-Diversity Check\n",
    "\n",
    "l = 2  # Minimum diversity level required\n",
    "sensitive_attr = \n",
    "\n",
    "l_diverse_groups = []\n",
    "non_diverse_groups = []\n",
    "\n",
    "for name, group in data.groupby(qi_columns):\n",
    "    diversity = \n",
    "    if diversity >= l:\n",
    "       \n",
    "    else:\n",
    "        \n",
    "# Print the Groups satisfying l-diversity and Groups violating l-diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Task 1.8 : Apply t-Closeness\n",
    "\n",
    "Prevent attribute disclosure by making sure that the distribution of sensitive values within each group is close to the global distribution (using Total Variation Distance).\n",
    "\n",
    "### ðŸ§¾ Instructions:\n",
    "- Compute global distribution of the sensitive attribute.\n",
    "- For each group:\n",
    "  - Compute local distribution.\n",
    "  - Compare with global distribution using Total Variation Distance (TVD).\n",
    "    $$\n",
    "             \\text{Distance} = \\frac{1}{2} \\sum_{i=1}^{n} \\left| P_i - Q_i \\right|\n",
    "    $$\n",
    "    Where:\n",
    "\n",
    "     - \\( P_i \\) = group distribution for class \\( i \\)  \n",
    "     - \\( Q_i \\) = global distribution for class \\( i \\)\n",
    "\n",
    "\n",
    "  - Flag groups where TVD > threshold t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sum as npsum\n",
    "\n",
    "#  t-Closeness Check\n",
    "\n",
    "t = 0.3  # Threshold for closeness\n",
    "t_violations = []\n",
    "\n",
    "# Global distribution\n",
    "global_dist = \n",
    "\n",
    "for name, group in data.groupby(qi_columns):\n",
    "    group_dist = \n",
    "    \n",
    "    # Align indices\n",
    "    group_dist = \n",
    "    \n",
    "    # Total Variation Distance (TVD)\n",
    "    distance = \n",
    "    \n",
    "    if distance > t:\n",
    "        \n",
    "# Print the  Groups violating t-closeness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§  Quiz Time \n",
    "### Q1. Which of the following correctly describes the relationship between these techniques?\n",
    "\n",
    "A. k-Anonymity is stricter than both l-Diversity and t-Closeness  \n",
    "B. l-Diversity and t-Closeness are enhancements to overcome k-Anonymity's limitations  \n",
    "C. t-Closeness can be applied without considering quasi-identifiers  \n",
    "D. All three techniques guarantee perfect privacy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ðŸ‘‰ **Type your selected option below:**  \n",
    "Your answer: `_____`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2: Text Anonymization with SpaCy (NER + Masking)\n",
    "\n",
    "### ðŸ’¡ Task 2 \n",
    "\n",
    "#### Description:\n",
    "You are provided with a dataset containing news headlines with columns: `publish_date`, `headline_category`, and `headline_text`. Your task is to anonymize the `headline_text` column using **Named Entity Recognition (NER)** to identify and mask named entities such as people, organizations, locations, and dates.\n",
    "\n",
    "Click ***[here](https://github.com/SanthwanaT/Seminar-3/blob/main/legal_text_classification.csv)***  to understand more about the dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ’¡ Task 2.1: Install and Import Required Libraries\n",
    "\n",
    "- Install spaCy and download the English language model.\n",
    "- Import necessary libraries (spaCy, pandas).\n",
    "\n",
    "### ðŸ§¾ Instructions:\n",
    "\n",
    "- SpaCy is not installed by default in Colab; you must install it first.\n",
    "- The English model (en_core_web_sm) is needed for NER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spaCy and download the model\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Import required libraries\n",
    "import spacy\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ’¡ Task 2.2: Load the Dataset\n",
    "\n",
    "- Upload the CSV file containing text data.\n",
    "- Load it using pandas.\n",
    "\n",
    "### ðŸ§¾ Instructions:\n",
    "\n",
    "Use the Colab file uploader to upload the dataset named legal_text_classification.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload CSV\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "data =\n",
    "\n",
    "# Preview the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ’¡ Task 2.3: Define the Anonymization Function\n",
    "\n",
    "- Write a function using spaCy to identify named entities and mask them with labels.\n",
    "- Handle missing or non-string data gracefully.\n",
    "\n",
    "### ðŸ§¾ Instructions:\n",
    "\n",
    "- Use spaCy's nlp() to process each text entry.\n",
    "- Replace named entities with [LABEL]. (eg : [\"PERSON\", \"GPE\", \"ORG\", \"LOC\", \"DATE\", \"TIME\", \"MONEY\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to anonymize named entities\n",
    "def anonymize_text(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ðŸ’¡ Task 2.4: Apply Anonymization and Save Output\n",
    "\n",
    "- Apply the anonymization function to the case_text column.\n",
    "- Save the anonymized dataset to a new CSV.\n",
    "- View anonymized examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the anonymization function\n",
    "data[\"Anonymized_Text\"] = \n",
    "\n",
    "# Save anonymized data\n",
    "\n",
    "# Display sample results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§  Quiz Time \n",
    "### Q1. Which of the following correctly describes the relationship between these techniques?\n",
    "\n",
    "A. Common nouns like \"city\", \"company\", \"year\"  \n",
    "B. Words like \"and\", \"the\", \"of\"                                                                                                                         \n",
    "C. Named entities like \"Barack Obama\", \"Google\", \"New York\"  \n",
    "D. Punctuation marks and stopword\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ðŸ‘‰ **Type your selected option below:**  \n",
    "Your answer: `_____`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 3:  Audio Data Anonymization\n",
    "\n",
    "Audio data anonymization refers to the process of altering audio data, such as voice recordings, to prevent the identification of the individual who produced the data while maintaining its overall utility for analysis. This is crucial for applications where personal audio data, such as speech recordings or voiceprints, are used. For example, in datasets like VoxCeleb, speaker identity can be easily inferred from voice features, making it essential to anonymize the audio in order to comply with privacy regulations\n",
    "\n",
    "\n",
    "### ðŸ’¡ Task 3\n",
    "\n",
    "#### Description:\n",
    "Anonymize audio data,by obscuring speaker identity while preserving the utility of the data for tasks like speech recognition, voice activity detection, or speaker verification.\n",
    "\n",
    "\n",
    "### ðŸ’¡ Task 3.1\n",
    "\n",
    "###  Audio Preprocessing and Pitch Shifting\n",
    "\n",
    "\n",
    "Start by loading an audio sample from the VoxCeleb dataset and applying a pitch shift to anonymize the speaker's voice.\n",
    "\n",
    "Note : Understand Voxceleb dataset by clicking here : [***here***](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/)\n",
    "\n",
    "#### **Instructions:**\n",
    "1. Load an audio sample from the dataset.\n",
    "\n",
    "2. Apply a pitch shift of +5 semitones to the audio.\n",
    "\n",
    "3. Visualize the waveform of the original and pitch-shifted audio.\n",
    "\n",
    "\n",
    "Use any of the [***audio files***](https://github.com/SanthwanaT/Seminar-3/tree/main/example%20datas%20from%20voxceleb) for task 3.1, 3.2, 3.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib \n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load audio file\n",
    "audio_path = \n",
    "audio, sr = \n",
    "\n",
    "# Apply pitch shifting (e.g., shift up by 4 semitones)\n",
    "\n",
    "# Plotting\n",
    "\n",
    "# Original waveform\n",
    "\n",
    "\n",
    "# Pitch-shifted waveform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ðŸ’¡ Task 3.2\n",
    "\n",
    "### Time Stretching for Anonymization\n",
    "\n",
    "Now, apply time stretching to alter the duration of the audio without changing its pitch. Choose a stretch rate of 1.2 (i.e., increase the length of the audio by 20%).\n",
    "\n",
    "#### **Instructions:**\n",
    "\n",
    "\n",
    "1. Apply time stretching to the same audio sample.\n",
    "\n",
    "2. Visualize the waveforms of the original and time-stretched audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = \n",
    "audio, sr = \n",
    "\n",
    "# Apply time stretching (increase duration by 20%)\n",
    "# A rate < 1 slows down (stretches), > 1 speeds up (compresses)\n",
    "stretch_rate = \n",
    "audio_stretched = \n",
    "\n",
    "# Plotting\n",
    "\n",
    "\n",
    "# Original waveform\n",
    "\n",
    "\n",
    "# Time-stretched waveform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Task 3.3 \n",
    "\n",
    "### Adding Noise to Anonymize the Audio\n",
    "\n",
    "Next, add background noise to the audio to further obscure the speakerâ€™s identity.\n",
    "\n",
    "#### **Instructions:**\n",
    "\n",
    "\n",
    "1. Generate some random noise and add it to the audio.\n",
    "   $$\n",
    "     \\text{noise} = \\text{randn}(L) \\times \\text{noise\\_factor}\n",
    "   $$\n",
    "   where L=len(audio)\n",
    "\n",
    "\n",
    "   $$\n",
    "     \\text{normalized\\_audio} = \\frac{\\text{audio\\_noisy}}{\\max\\left(|\\text{audio\\_noisy}|\\right)}\n",
    "   $$\n",
    "\n",
    "\n",
    "\n",
    "2. Visualize the waveforms of the original and noisy audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = \n",
    "audio, sr = \n",
    "\n",
    "# Generate white noise\n",
    "noise_factor = 0.005  # Adjust for more or less noise\n",
    "noise = \n",
    "\n",
    "# Add noise to the original audio\n",
    "audio_noisy = \n",
    "\n",
    "# Normalize to prevent clipping\n",
    "audio_noisy = \n",
    "\n",
    "# Plotting\n",
    "\n",
    "# Original waveform\n",
    "\n",
    "\n",
    "# Noisy waveform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code, reflect on the following:\n",
    "- Audio Quality: Is the audio still understandable after anonymization?\n",
    "\n",
    "\n",
    "- Speaker Anonymity: Can you identify the speaker from the anonymized audio?\n",
    "\n",
    "- Preservation of Content: Does the anonymized audio still convey the intended information (e.g., speech recognition, speaker verification)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
