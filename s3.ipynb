{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Anonymization and Privacy-Enhancing Technologies (PETs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Learning Goals\n",
    "- Understand what data anonymization is and why it matters.\n",
    "- Apply anonymization techniques to structured, text and audio data.\n",
    "- Understand how anonymization supports compliance with privacy laws (GDPR, CCPA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ” Introduction to Data Anonymization\n",
    "\n",
    "- **Data anonymization** removes personally identifiable information (PII) from datasets.\n",
    "- **Pseudonymization** retains a link to identity (e.g., using a key); anonymization does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§° Techniques for Anonymizing Different Data Types\n",
    "- **Structured Data**: k-anonymity, l-diversity, t-closeness\n",
    "- **Text Data**: Named Entity Recognition (NER) + masking\n",
    "- **Images**: Face blurring, pixelation\n",
    "- **Audio**: Voice masking, pitch shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“œ Legal Relevance\n",
    "- **GDPR & CCPA**: Require data minimization and protection.\n",
    "- Anonymization helps avoid processing 'personal data' under these laws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 1: Structured Data Anonymization (k-Anonymity)\n",
    "\n",
    "### ðŸ’¡ Task 1 \n",
    "\n",
    "#### Description:\n",
    "You are provided with a structured dataset (CSV file) containing personal attributes like Age, Education, Occupation, Relationship, Sex, and Country. Your task is to anonymize this data using **k-anonymity** by binning continuous data (like Age) and generalizing or masking quasi-identifiers such as Country or Occupation. Then assess whether individual identities could still be inferred.\n",
    "\n",
    "\n",
    "- Generalize and group quasi-identifiers (e.g., Age and Country)\n",
    "- Ensure each combination of quasi-identifiers occurs at least **k** times\n",
    "- Evaluate anonymity level before and after transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn spacy opencv-python-headless matplotlib librosa pydub\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from collections import Counter\n",
    "from google.colab import files\n",
    "\n",
    "# Upload CSV file\n",
    "display(\"Upload your structured dataset CSV\")\n",
    "uploaded = files.upload()\n",
    "filename = next(iter(uploaded))\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "# Bin Age into categories\n",
    "binner = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "data['Age_group'] = binner.fit_transform(data[['Age']]).astype(int)\n",
    "\n",
    "# Generalize Country\n",
    "region_map = {\n",
    "    'United-States': 'North America', 'Canada': 'North America', 'Mexico': 'North America',\n",
    "    'India': 'Asia', 'China': 'Asia', 'Japan': 'Asia',\n",
    "    'Germany': 'Europe', 'France': 'Europe', 'UK': 'Europe'\n",
    "}\n",
    "data['Region'] = data['Country'].map(region_map).fillna('Other')\n",
    "\n",
    "# Drop specific identifying columns\n",
    "data = data.drop(columns=['Age', 'Country'])\n",
    "\n",
    "# Group by quasi-identifiers and count\n",
    "qi_cols = ['Age_group', 'Region', 'Sex']\n",
    "k_anon_counts = data.groupby(qi_cols).size().reset_index(name='Count')\n",
    "\n",
    "# Merge back counts to each record\n",
    "data = pd.merge(data, k_anon_counts, on=qi_cols)\n",
    "\n",
    "# Check if k-anonymity condition is met (e.g., k >= 3)\n",
    "k = 3\n",
    "print(f\"Rows violating {k}-anonymity:\")\n",
    "print(data[data['Count'] < k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2: Text Anonymization with SpaCy (NER + Masking)\n",
    "\n",
    "### ðŸ’¡ Task 2 \n",
    "\n",
    "#### Description:\n",
    "You are provided with a dataset containing news headlines with columns: `publish_date`, `headline_category`, and `headline_text`. Your task is to anonymize the `headline_text` column using **Named Entity Recognition (NER)** to identify and mask named entities such as people, organizations, locations, and dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "\n",
    "# Load NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Upload CSV dataset\n",
    "uploaded = files.upload()\n",
    "filename = next(iter(uploaded))\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Function to anonymize a single headline\n",
    "def anonymize_text(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        text = text.replace(ent.text, f\"<MASK_{ent.label_}>\")\n",
    "    return text\n",
    "\n",
    "# Apply anonymization to the dataset\n",
    "df['anonymized_headline'] = df['headline_text'].apply(anonymize_text)\n",
    "\n",
    "# Display a few results\n",
    "df[['headline_text', 'anonymized_headline']].head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
